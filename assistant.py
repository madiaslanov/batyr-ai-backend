# assistant.py
import os
import io
import json
import base64
import logging
import datetime
import hmac
import hashlib
from urllib.parse import unquote
from dotenv import load_dotenv
from fastapi import FastAPI, HTTPException, UploadFile, File, Form, Depends, Security
from fastapi.security import APIKeyHeader
from fastapi.middleware.cors import CORSMiddleware
import azure.cognitiveservices.speech as speechsdk
from openai import AzureOpenAI
from typing import List, Dict
from pydub import AudioSegment
from pydantic import BaseModel, Field

# --- 1. –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è ---
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# --- 2. –ó–∞–≥—Ä—É–∑–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –∏ –∫–æ–Ω—Å—Ç–∞–Ω—Ç—ã ---
load_dotenv()
SPEECH_KEY = os.getenv("SPEECH_KEY")
SPEECH_REGION = os.getenv("SPEECH_REGION")
SPEECH_VOICE_NAME = "kk-KZ-DauletNeural"
SPEECH_RECOGNITION_LANGUAGE = "kk-KZ"
AZURE_OPENAI_KEY = os.getenv("AZURE_OPENAI_KEY")
AZURE_OPENAI_ENDPOINT = os.getenv("AZURE_OPENAI_ENDPOINT")
OPENAI_API_VERSION = os.getenv("OPENAI_API_VERSION")
AZURE_OPENAI_DEPLOYMENT_NAME = os.getenv("AZURE_OPENAI_DEPLOYMENT_NAME")
SYSTEM_PROMPT = "–°–µ–Ω ‚Äì —Ç–∞—Ä–∏—Ö –ø”ô–Ω—ñ–Ω—ñ“£ —Å–∞—Ä–∞–ø—à—ã—Å—ã, –ë–∞—Ç—ã—Ä –∞—Ç—Ç—ã AI-–∫”©–º–µ–∫—à—ñ—Å—ñ“£. “ö—ã—Å“õ–∞, “õ“±—Ä–º–µ—Ç–ø–µ–Ω –∂”ô–Ω–µ –º”ô–Ω—ñ –±–æ–π—ã–Ω—à–∞ –∂–∞—É–∞–ø –±–µ—Ä. –û—Ç–≤–µ—á–∞–π 1-2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è–º–∏. –°–µ–Ω—ñ“£ –º—ñ–Ω–¥–µ—Ç—ñ“£ ‚Äì –±—ñ–ª—ñ–º –±–µ—Ä—É."

# --- 3. –ü—Ä–æ–≤–µ—Ä–∫–∏ –∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∏–µ–Ω—Ç–æ–≤ ---
if not all([SPEECH_KEY, SPEECH_REGION, AZURE_OPENAI_KEY, AZURE_OPENAI_ENDPOINT, OPENAI_API_VERSION, AZURE_OPENAI_DEPLOYMENT_NAME]):
    raise RuntimeError("–û–¥–Ω–∞ –∏–ª–∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è Azure –Ω–µ –∑–∞–¥–∞–Ω—ã.")

try:
    AZURE_OPENAI_CLIENT = AzureOpenAI(api_key=AZURE_OPENAI_KEY, api_version=OPENAI_API_VERSION, azure_endpoint=AZURE_OPENAI_ENDPOINT)
    logging.info("–ö–ª–∏–µ–Ω—Ç Azure OpenAI —É—Å–ø–µ—à–Ω–æ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω.")
except Exception as e:
    logging.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∫–ª–∏–µ–Ω—Ç Azure OpenAI: {e}")
    raise

# --- 4. Pydantic-–º–æ–¥–µ–ª–∏ ---
class AssistantResponse(BaseModel):
    userText: str = Field(..., description="–†–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.")
    assistantText: str = Field(..., description="–¢–µ–∫—Å—Ç–æ–≤—ã–π –æ—Ç–≤–µ—Ç –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞.")
    audioBase64: str = Field(..., description="–ê—É–¥–∏–æ–æ—Ç–≤–µ—Ç –≤ —Ñ–æ—Ä–º–∞—Ç–µ Base64.")

# --- 5. –ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ FastAPI —Å —É—Å–ª–æ–≤–Ω—ã–º –æ—Ç–∫–ª—é—á–µ–Ω–∏–µ–º –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ ---
ENVIRONMENT = os.getenv("ENVIRONMENT", "development")
fastapi_kwargs = {"title": "Batyr AI Assistant API", "description": "–û—Ç–¥–µ–ª—å–Ω—ã–π —Å–µ—Ä–≤–∏—Å –¥–ª—è –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ AI-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞.", "version": "1.0.0"}
if ENVIRONMENT == "production":
    fastapi_kwargs.update({"docs_url": None, "redoc_url": None, "openapi_url": None})
    logging.info("Assistant: 'production' mode. API docs disabled.")
else:
    logging.info("Assistant: 'development' mode. API docs available.")
app = FastAPI(**fastapi_kwargs)

app.add_middleware(CORSMiddleware, allow_origins=["*"], allow_credentials=True, allow_methods=["*"], allow_headers=["*"])

# --- ‚úÖ –ù–æ–≤–∞—è —Å–µ–∫—Ü–∏—è –∑–∞—â–∏—Ç—ã API —á–µ—Ä–µ–∑ Telegram initData ---
BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
if not BOT_TOKEN:
    raise RuntimeError("TELEGRAM_BOT_TOKEN –Ω–µ –∑–∞–¥–∞–Ω! –°–µ—Ä–≤–∏—Å –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –∑–∞–ø—É—â–µ–Ω –±–µ–∑–æ–ø–∞—Å–Ω–æ.")

telegram_init_data_header = APIKeyHeader(name="X-Telegram-Init-Data", auto_error=False)

async def get_validated_telegram_data(init_data: str = Security(telegram_init_data_header)):
    if not init_data:
        raise HTTPException(status_code=401, detail="X-Telegram-Init-Data header is missing")
    try:
        unquoted_init_data = unquote(init_data)
        data_check_string, hash_from_telegram = [], ''
        for item in sorted(unquoted_init_data.split('&')):
            key, value = item.split('=', 1)
            if key == 'hash':
                hash_from_telegram = value
            else:
                data_check_string.append(f"{key}={value}")
        data_check_string = "\n".join(data_check_string)
        secret_key = hmac.new("WebAppData".encode(), BOT_TOKEN.encode(), hashlib.sha256).digest()
        calculated_hash = hmac.new(secret_key, data_check_string.encode(), hashlib.sha256).hexdigest()
        if calculated_hash != hash_from_telegram:
            raise HTTPException(status_code=403, detail="Invalid data signature")
        user_data_str = dict(kv.split('=') for kv in unquoted_init_data.split('&')).get('user', '{}')
        return json.loads(user_data_str)
    except Exception as e:
        logging.warning(f"–û—à–∏–±–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ Telegram initData: {e}")
        raise HTTPException(status_code=403, detail="Could not validate Telegram credentials.")

# --- 6. –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ ---
def recognize_speech_from_bytes(audio_bytes: bytes, original_filename: str) -> str:
    logging.info(f"–ù–∞—á–∞–ª–æ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ä–µ—á–∏. –ü–æ–ª—É—á–µ–Ω–æ –±–∞–π—Ç–æ–≤: {len(audio_bytes)}")
    timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
    temp_audio_dir = "temp_audio"
    os.makedirs(temp_audio_dir, exist_ok=True)
    try:
        audio_segment = AudioSegment.from_file(io.BytesIO(audio_bytes))
        audio_segment = audio_segment.set_channels(1).set_frame_rate(16000)
        wav_filepath = os.path.join(temp_audio_dir, f"to_azure_{timestamp}.wav")
        audio_segment.export(wav_filepath, format="wav")
    except Exception as e:
        logging.error(f"üî• –û—à–∏–±–∫–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ –∞—É–¥–∏–æ: {e}", exc_info=True)
        raise ValueError("–ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –∞—É–¥–∏–æ—Ñ–∞–π–ª.")
    try:
        speech_config = speechsdk.SpeechConfig(subscription=SPEECH_KEY, region=SPEECH_REGION, speech_recognition_language=SPEECH_RECOGNITION_LANGUAGE)
        audio_config = speechsdk.audio.AudioConfig(filename=wav_filepath)
        recognizer = speechsdk.SpeechRecognizer(speech_config=speech_config, audio_config=audio_config)
        result = recognizer.recognize_once_async().get()
    finally:
        try:
            os.remove(wav_filepath)
        except OSError as e:
            logging.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª {wav_filepath}: {e}")
    if result.reason == speechsdk.ResultReason.RecognizedSpeech:
        if not result.text or result.text.isspace(): raise ValueError("–†–∞—Å–ø–æ–∑–Ω–∞–Ω –ø—É—Å—Ç–æ–π —Ç–µ–∫—Å—Ç.")
        logging.info(f"‚úÖ –†–∞—Å–ø–æ–∑–Ω–∞–Ω–æ: '{result.text}'")
        return result.text
    elif result.reason == speechsdk.ResultReason.NoMatch: raise ValueError("–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å —Ä–µ—á—å.")
    elif result.reason == speechsdk.ResultReason.Canceled:
        cancellation_details = result.cancellation_details
        logging.error(f"–û—à–∏–±–∫–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è (Canceled): {cancellation_details.reason}. –î–µ—Ç–∞–ª–∏: {cancellation_details.error_details}")
        if cancellation_details.error_code == speechsdk.CancellationErrorCode.AuthenticationFailure:
            raise RuntimeError("–û—à–∏–±–∫–∞ –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏ Azure. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ SPEECH_KEY –∏ SPEECH_REGION.")
        raise RuntimeError(f"–û—à–∏–±–∫–∞ —Å–µ—Ä–≤–∏—Å–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è: {cancellation_details.reason}")
    raise RuntimeError("–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–∏ —Ä–µ—á–∏.")

def get_answer_from_llm(question: str, history: List[Dict[str, str]]) -> str:
    messages = [{"role": "system", "content": SYSTEM_PROMPT}] + history + [{"role": "user", "content": question}]
    try:
        response = AZURE_OPENAI_CLIENT.chat.completions.create(model=AZURE_OPENAI_DEPLOYMENT_NAME, messages=messages, temperature=0.7, max_tokens=80)
        answer = response.choices[0].message.content
        logging.info(f"–û—Ç–≤–µ—Ç –æ—Ç LLM –ø–æ–ª—É—á–µ–Ω: '{answer[:50]}...'")
        return answer
    except Exception as e:
        logging.error(f"üî• –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ Azure OpenAI: {e}", exc_info=True)
        raise RuntimeError("–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ —Å–µ—Ä–≤–∏—Å—É OpenAI.")

def synthesize_speech_from_text(text: str) -> bytes:
    speech_config = speechsdk.SpeechConfig(subscription=SPEECH_KEY, region=SPEECH_REGION)
    speech_config.speech_synthesis_voice_name = SPEECH_VOICE_NAME
    speech_config.set_speech_synthesis_output_format(speechsdk.SpeechSynthesisOutputFormat.Audio16Khz32KBitRateMonoMp3)
    synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config, audio_config=None)
    result = synthesizer.speak_text_async(text).get()
    if result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted: return result.audio_data
    raise RuntimeError(f"–û—à–∏–±–∫–∞ —Å–∏–Ω—Ç–µ–∑–∞ —Ä–µ—á–∏: {result.cancellation_details.reason}")

# --- 7. –§–∏–Ω–∞–ª—å–Ω—ã–π —ç–Ω–¥–ø–æ–∏–Ω—Ç —Å –Ω–æ–≤–æ–π –∑–∞—â–∏—Ç–æ–π ---
@app.post("/api/ask-assistant", response_model=AssistantResponse, dependencies=[Depends(get_validated_telegram_data)])
async def ask_assistant(audio_file: UploadFile = File(...), history_json: str = Form("[]")):
    try:
        history = json.loads(history_json) if isinstance(history_json, str) else []
        if not isinstance(history, list): history = []
        audio_bytes = await audio_file.read()
        recognized_text = recognize_speech_from_bytes(audio_bytes, audio_file.filename)
        answer_text = get_answer_from_llm(recognized_text, history)
        answer_audio_bytes = synthesize_speech_from_text(answer_text)
        audio_base64 = base64.b64encode(answer_audio_bytes).decode('utf-8')
        return AssistantResponse(userText=recognized_text, assistantText=answer_text, audioBase64=audio_base64)
    except ValueError as e:
        logging.warning(f"–û—à–∏–±–∫–∞ –¥–∞–Ω–Ω—ã—Ö –æ—Ç –∫–ª–∏–µ–Ω—Ç–∞ (400): {e}")
        raise HTTPException(status_code=400, detail=str(e))
    except Exception as e:
        logging.error("–ù–µ–ø—Ä–µ–¥–≤–∏–¥–µ–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –≤ /api/ask-assistant", exc_info=True)
        raise HTTPException(status_code=500, detail="–ü—Ä–æ–∏–∑–æ—à–ª–∞ –Ω–µ–ø—Ä–µ–¥–≤–∏–¥–µ–Ω–Ω–∞—è –≤–Ω—É—Ç—Ä–µ–Ω–Ω—è—è –æ—à–∏–±–∫–∞ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞.")