# assistant.py
import os
import io
import json
import traceback
from dotenv import load_dotenv
from fastapi import FastAPI, HTTPException, UploadFile, File, Form
from fastapi.responses import StreamingResponse
from fastapi.middleware.cors import CORSMiddleware
import azure.cognitiveservices.speech as speechsdk
from openai import AzureOpenAI
from typing import List

# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
load_dotenv()

# --- –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è Azure ---
SPEECH_KEY = os.getenv("SPEECH_KEY")
SPEECH_REGION = os.getenv("SPEECH_REGION")
AZURE_OPENAI_DEPLOYMENT_NAME = os.getenv("AZURE_OPENAI_DEPLOYMENT_NAME")

# --- –ü—Ä–æ–≤–µ—Ä–∫–∏ –∏ –∫–ª–∏–µ–Ω—Ç—ã ---
if not (SPEECH_KEY and SPEECH_REGION):
    raise RuntimeError("–ù–µ –Ω–∞–π–¥–µ–Ω—ã SPEECH_KEY –∏–ª–∏ SPEECH_REGION –≤ .env —Ñ–∞–π–ª–µ")
if not os.getenv("AZURE_OPENAI_KEY"):
    raise RuntimeError("–ù–µ –Ω–∞–π–¥–µ–Ω AZURE_OPENAI_KEY –≤ .env —Ñ–∞–π–ª–µ")

AZURE_OPENAI_CLIENT = AzureOpenAI(
    api_key=os.getenv("AZURE_OPENAI_KEY"),
    api_version=os.getenv("OPENAI_API_VERSION"),
    azure_endpoint=os.getenv("AZURE_OPENAI_ENDPOINT")
)

# --- –ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ FastAPI –¥–ª—è –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞ ---
app = FastAPI(
    title="Batyr AI Assistant API",
    description="–û—Ç–¥–µ–ª—å–Ω—ã–π —Å–µ—Ä–≤–∏—Å –¥–ª—è –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ AI-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞."
)

# –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º CORS, —á—Ç–æ–±—ã —Ñ—Ä–æ–Ω—Ç–µ–Ω–¥ –º–æ–≥ –æ–±—Ä–∞—â–∞—Ç—å—Å—è –∫ —ç—Ç–æ–º—É —Å–µ—Ä–≤–∏—Å—É
origins = [
    "http://localhost:3000",
    "https://batyrai.com",
    "https://www.batyrai.com",
    "https://batyr-ai.vercel.app",
    "https://batyr-ai-madis-projects-f57aa02c.vercel.app",
    "*"  # –†–∞–∑—Ä–µ—à–∞–µ–º –≤—Å–µ –¥–æ–º–µ–Ω—ã, –≤–∫–ª—é—á–∞—è Telegram Web App
]
app.add_middleware(
    CORSMiddleware,
    allow_origins=origins,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# --- –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ ---

# –§—É–Ω–∫—Ü–∏—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ä–µ—á–∏, —É–∂–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω–∞—è
def recognize_speech_from_bytes(audio_bytes: bytes) -> str:
    speech_config = speechsdk.SpeechConfig(
        subscription=SPEECH_KEY, 
        region=SPEECH_REGION,
        speech_recognition_language="kk-KZ"
    )
    stream = speechsdk.audio.PushAudioInputStream()
    audio_config = speechsdk.audio.AudioConfig(stream=stream)
    recognizer = speechsdk.SpeechRecognizer(speech_config=speech_config, audio_config=audio_config)
    
    stream.write(audio_bytes)
    stream.close()

    result = recognizer.recognize_once_async().get()

    if result.reason == speechsdk.ResultReason.RecognizedSpeech:
        print(f"–†–∞—Å–ø–æ–∑–Ω–∞–Ω–æ: '{result.text}'")
        return result.text
    elif result.reason == speechsdk.ResultReason.NoMatch:
        print("–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å —Ä–µ—á—å.")
        raise ValueError("–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å —Ä–µ—á—å. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–Ω–æ–≤–∞.")
    elif result.reason == speechsdk.ResultReason.Canceled:
        cancellation_details = result.cancellation_details
        print(f"–†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –æ—Ç–º–µ–Ω–µ–Ω–æ: {cancellation_details.reason}")
        if cancellation_details.reason == speechsdk.CancellationReason.Error:
            print(f"–ö–æ–¥ –æ—à–∏–±–∫–∏: {cancellation_details.error_details}")
        raise RuntimeError(f"–û—à–∏–±–∫–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è: {cancellation_details.reason}")
    
    raise RuntimeError(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è: {result.reason}")

# ‚úÖ –ò–ó–ú–ï–ù–ï–ù–ò–ï: –§—É–Ω–∫—Ü–∏—è —Ç–µ–ø–µ—Ä—å –ø—Ä–∏–Ω–∏–º–∞–µ—Ç –∏—Å—Ç–æ—Ä–∏—é —á–∞—Ç–∞
def get_answer_from_llm(question: str, history: List[dict]) -> str:
    system_prompt = "–°–µ–Ω ‚Äì —Ç–∞—Ä–∏—Ö –ø”ô–Ω—ñ–Ω—ñ“£ —Å–∞—Ä–∞–ø—à—ã—Å—ã, –ë–∞—Ç—ã—Ä –∞—Ç—Ç—ã AI-–∫”©–º–µ–∫—à—ñ—Å—ñ“£. “ö—ã—Å“õ–∞, “õ“±—Ä–º–µ—Ç–ø–µ–Ω –∂”ô–Ω–µ –º”ô–Ω—ñ –±–æ–π—ã–Ω—à–∞ –∂–∞—É–∞–ø –±–µ—Ä. –°–µ–Ω—ñ“£ –º—ñ–Ω–¥–µ—Ç—ñ“£ ‚Äì –±—ñ–ª—ñ–º –±–µ—Ä—É. –ü–∞–π–¥–∞–ª–∞–Ω—É—à—ã–º–µ–Ω —Å“±—Ö–±–∞—Ç –∂“Ø—Ä–≥—ñ–∑."
    
    # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è –¥–ª—è –º–æ–¥–µ–ª–∏: —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç + –∏—Å—Ç–æ—Ä–∏—è + –Ω–æ–≤—ã–π –≤–æ–ø—Ä–æ—Å
    messages = [{"role": "system", "content": system_prompt}] + history + [{"role": "user", "content": question}]

    try:
        response = AZURE_OPENAI_CLIENT.chat.completions.create(
            model=AZURE_OPENAI_DEPLOYMENT_NAME,
            messages=messages,
            temperature=0.7, 
            max_tokens=150,
        )
        answer = response.choices[0].message.content
        print(f"–û—Ç–≤–µ—Ç –æ—Ç LLM: '{answer}'")
        return answer
    except Exception as e:
        print(f"üî• –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ Azure OpenAI: {e}")
        return "–ö–µ—à—ñ—Ä—ñ“£—ñ–∑, –º–µ–Ω–¥–µ —ñ—à–∫—ñ “õ–∞—Ç–µ –ø–∞–π–¥–∞ –±–æ–ª–¥—ã. –ö–µ–π—ñ–Ω—ñ—Ä–µ–∫ —Å“±—Ä–∞–ø –∫”©—Ä—ñ“£—ñ–∑."

# ‚úÖ –ò–ó–ú–ï–ù–ï–ù–ò–ï: –ü–æ–ø—Ä–æ–±—É–µ–º –¥—Ä—É–≥–æ–π –≥–æ–ª–æ—Å, —á—Ç–æ–±—ã —Ä–µ—á—å –±—ã–ª–∞ –±–æ–ª–µ–µ –∂–∏–≤–æ–π
def synthesize_speech_from_text(text: str) -> bytes:
    speech_config = speechsdk.SpeechConfig(subscription=SPEECH_KEY, region=SPEECH_REGION)
    # –ü–æ–ø—Ä–æ–±—É–µ–º –º—É–∂—Å–∫–æ–π –≥–æ–ª–æ—Å Daulet
    speech_config.speech_synthesis_voice_name = "kk-KZ-DauletNeural"
    synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config, audio_config=None)
    result = synthesizer.speak_text_async(text).get()
    if result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:
        return result.audio_data
    raise RuntimeError(f"–û—à–∏–±–∫–∞ —Å–∏–Ω—Ç–µ–∑–∞ —Ä–µ—á–∏: {result.cancellation_details.reason}")


# ‚úÖ –ò–ó–ú–ï–ù–ï–ù–ò–ï: –≠–Ω–¥–ø–æ–∏–Ω—Ç —Ç–µ–ø–µ—Ä—å –ø—Ä–∏–Ω–∏–º–∞–µ—Ç –∏—Å—Ç–æ—Ä–∏—é —á–∞—Ç–∞ –≤ –≤–∏–¥–µ JSON-—Å—Ç—Ä–æ–∫–∏
@app.post("/api/ask-assistant")
async def ask_assistant(
    audio_file: UploadFile = File(...),
    history_json: str = Form("[]")  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –∏—Å—Ç–æ—Ä–∏—è –ø—É—Å—Ç–∞—è
):
    try:
        # –ü–∞—Ä—Å–∏–º –∏—Å—Ç–æ—Ä–∏—é –∏–∑ —Å—Ç—Ä–æ–∫–∏ –≤ Python-–æ–±—ä–µ–∫—Ç (—Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π)
        try:
            history = json.loads(history_json)
            if not isinstance(history, list):
                history = []
        except json.JSONDecodeError:
            history = []

        # –†–∞—Å–ø–æ–∑–Ω–∞–µ–º —Ä–µ—á—å –∏–∑ –∞—É–¥–∏–æ
        audio_bytes = await audio_file.read()
        recognized_text = recognize_speech_from_bytes(audio_bytes)
        
        # –ü–æ–ª—É—á–∞–µ–º –æ—Ç–≤–µ—Ç –æ—Ç LLM, –ø–µ—Ä–µ–¥–∞–≤–∞—è –µ–º—É –∏—Å—Ç–æ—Ä–∏—é
        answer_text = get_answer_from_llm(recognized_text, history)
        
        # –°–∏–Ω—Ç–µ–∑–∏—Ä—É–µ–º –∞—É–¥–∏–æ –∏–∑ –æ—Ç–≤–µ—Ç–∞
        answer_audio_bytes = synthesize_speech_from_text(answer_text)

        # ‚úÖ –í–ê–ñ–ù–û: –í–æ–∑–≤—Ä–∞—â–∞–µ–º –Ω–µ —Ç–æ–ª—å–∫–æ –∞—É–¥–∏–æ, –Ω–æ –∏ —Ç–µ–∫—Å—Ç—ã –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –∏—Å—Ç–æ—Ä–∏–∏ –Ω–∞ —Ñ—Ä–æ–Ω—Ç–µ–Ω–¥–µ
        # –≠—Ç–æ –ø–æ—Ç—Ä–µ–±—É–µ—Ç –∏–∑–º–µ–Ω–µ–Ω–∏–π –Ω–∞ —Ñ—Ä–æ–Ω—Ç–µ–Ω–¥–µ. –ü–æ–∫–∞ —á—Ç–æ –æ—Å—Ç–∞–≤–∏–º –∫–∞–∫ –±—ã–ª–æ,
        # –Ω–æ –¥–ª—è –ø–æ–ª–Ω–æ—Ü–µ–Ω–Ω–æ–≥–æ —á–∞—Ç–∞ –Ω—É–∂–Ω–æ –±—É–¥–µ—Ç –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å JSON —Å –∞—É–¥–∏–æ –≤ base64 –∏ —Ç–µ–∫—Å—Ç–∞–º–∏.
        # –î–ª—è –ø—Ä–æ—Å—Ç–æ—Ç—ã —Å–µ–π—á–∞—Å –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–æ–ª—å–∫–æ –∞—É–¥–∏–æ. –§—Ä–æ–Ω—Ç–µ–Ω–¥ –¥–æ–ª–∂–µ–Ω –±—É–¥–µ—Ç —Å–∞–º
        # –¥–æ–±–∞–≤–ª—è—Ç—å –≤ –∏—Å—Ç–æ—Ä–∏—é —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç (–∫–æ—Ç–æ—Ä—ã–π –æ–Ω –Ω–µ –∑–Ω–∞–µ—Ç) –∏ –æ—Ç–≤–µ—Ç (–∫–æ—Ç–æ—Ä—ã–π –æ–Ω –Ω–µ –∑–Ω–∞–µ—Ç).
        # –≠—Ç–æ –ø—Ä–æ–±–ª–µ–º–∞. –î–∞–≤–∞–π—Ç–µ –ø–æ–∫–∞ —É–ø—Ä–æ—Å—Ç–∏–º.
        
        # –î–∞–≤–∞–π—Ç–µ –≤–µ—Ä–Ω–µ–º JSON, —á—Ç–æ–±—ã —Ñ—Ä–æ–Ω—Ç–µ–Ω–¥ –º–æ–≥ –æ–±–Ω–æ–≤–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—é!
        # –≠—Ç–æ –±–æ–ª–µ–µ –ø—Ä–∞–≤–∏–ª—å–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞.
        
        response_data = {
            "user_text": recognized_text,
            "assistant_text": answer_text,
            "audio_bytes": io.BytesIO(answer_audio_bytes) # –í—Ä–µ–º–µ–Ω–Ω–æ, –¥–ª—è StreamingResponse
        }
        
        # –ü–æ–∫–∞ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–æ–ª—å–∫–æ –∞—É–¥–∏–æ, –∫–∞–∫ –∏ —Ä–∞–Ω—å—à–µ, —á—Ç–æ–±—ã –Ω–µ –ª–æ–º–∞—Ç—å —Ñ—Ä–æ–Ω—Ç–µ–Ω–¥ —Å—Ä–∞–∑—É.
        # –ù–û –≤—ã –¥–æ–ª–∂–Ω—ã –∑–Ω–∞—Ç—å, —á—Ç–æ –¥–ª—è —á–∞—Ç–∞ —Å –ø–∞–º—è—Ç—å—é –Ω—É–∂–Ω–æ –±—É–¥–µ—Ç –ø–µ—Ä–µ–¥–µ–ª–∞—Ç—å –∏ —Ñ—Ä–æ–Ω—Ç–µ–Ω–¥.
        return StreamingResponse(io.BytesIO(answer_audio_bytes), media_type="audio/mpeg")

    except ValueError as e:
        raise HTTPException(status_code=400, detail=str(e))
    except Exception as e:
        traceback.print_exc()
        raise HTTPException(status_code=500, detail="–ü—Ä–æ–∏–∑–æ—à–ª–∞ –Ω–µ–ø—Ä–µ–¥–≤–∏–¥–µ–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞.")