# assistant.py
import os
import io
import json
import base64
import logging
import datetime  # –î–æ–±–∞–≤–ª–µ–Ω –∏–º–ø–æ—Ä—Ç –¥–ª—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –º–µ—Ç–æ–∫
from dotenv import load_dotenv
from fastapi import FastAPI, HTTPException, UploadFile, File, Form
from fastapi.middleware.cors import CORSMiddleware
import azure.cognitiveservices.speech as speechsdk
from openai import AzureOpenAI
from typing import List, Dict
from pydub import AudioSegment
from pydantic import BaseModel, Field

# --- 1. –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è ---
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)

# --- 2. –ó–∞–≥—Ä—É–∑–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –∏ –∫–æ–Ω—Å—Ç–∞–Ω—Ç—ã ---
load_dotenv()

SPEECH_KEY = os.getenv("SPEECH_KEY")
SPEECH_REGION = os.getenv("SPEECH_REGION")
SPEECH_VOICE_NAME = "kk-KZ-DauletNeural"
SPEECH_RECOGNITION_LANGUAGE = "kk-KZ"

AZURE_OPENAI_KEY = os.getenv("AZURE_OPENAI_KEY")
AZURE_OPENAI_ENDPOINT = os.getenv("AZURE_OPENAI_ENDPOINT")
OPENAI_API_VERSION = os.getenv("OPENAI_API_VERSION")
AZURE_OPENAI_DEPLOYMENT_NAME = os.getenv("AZURE_OPENAI_DEPLOYMENT_NAME")

SYSTEM_PROMPT = "–°–µ–Ω ‚Äì —Ç–∞—Ä–∏—Ö –ø”ô–Ω—ñ–Ω—ñ“£ —Å–∞—Ä–∞–ø—à—ã—Å—ã, –ë–∞—Ç—ã—Ä –∞—Ç—Ç—ã AI-–∫”©–º–µ–∫—à—ñ—Å—ñ“£. “ö—ã—Å“õ–∞, “õ“±—Ä–º–µ—Ç–ø–µ–Ω –∂”ô–Ω–µ –º”ô–Ω—ñ –±–æ–π—ã–Ω—à–∞ –∂–∞—É–∞–ø –±–µ—Ä. –°–µ–Ω—ñ“£ –º—ñ–Ω–¥–µ—Ç—ñ“£ ‚Äì –±—ñ–ª—ñ–º –±–µ—Ä—É. –ü–∞–π–¥–∞–ª–∞–Ω—É—à—ã–º–µ–Ω —Å“±—Ö–±–∞—Ç –∂“Ø—Ä–≥—ñ–∑."

# --- 3. –ü—Ä–æ–≤–µ—Ä–∫–∏ –∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∏–µ–Ω—Ç–æ–≤ ---
if not all([SPEECH_KEY, SPEECH_REGION, AZURE_OPENAI_KEY, AZURE_OPENAI_ENDPOINT, OPENAI_API_VERSION, AZURE_OPENAI_DEPLOYMENT_NAME]):
    raise RuntimeError("–û–¥–Ω–∞ –∏–ª–∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è –Ω–µ –∑–∞–¥–∞–Ω—ã. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ .env —Ñ–∞–π–ª.")

try:
    AZURE_OPENAI_CLIENT = AzureOpenAI(
        api_key=AZURE_OPENAI_KEY,
        api_version=OPENAI_API_VERSION,
        azure_endpoint=AZURE_OPENAI_ENDPOINT
    )
    logging.info("–ö–ª–∏–µ–Ω—Ç Azure OpenAI —É—Å–ø–µ—à–Ω–æ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω.")
except Exception as e:
    logging.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∫–ª–∏–µ–Ω—Ç Azure OpenAI: {e}")
    raise

# --- 4. Pydantic-–º–æ–¥–µ–ª–∏ ---
class AssistantResponse(BaseModel):
    userText: str = Field(..., description="–†–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.")
    assistantText: str = Field(..., description="–¢–µ–∫—Å—Ç–æ–≤—ã–π –æ—Ç–≤–µ—Ç –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞.")
    audioBase64: str = Field(..., description="–ê—É–¥–∏–æ–æ—Ç–≤–µ—Ç –≤ —Ñ–æ—Ä–º–∞—Ç–µ Base64.")

# --- 5. –ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ FastAPI ---
app = FastAPI(
    title="Batyr AI Assistant API",
    description="–û—Ç–¥–µ–ª—å–Ω—ã–π —Å–µ—Ä–≤–∏—Å –¥–ª—è –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ AI-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞.",
    version="1.0.0"
)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# --- 6. –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ ---

# ‚≠ê‚≠ê‚≠ê –ò–ó–ú–ï–ù–ï–ù–ù–ê–Ø –§–£–ù–ö–¶–ò–Ø –î–õ–Ø –û–¢–õ–ê–î–ö–ò ‚≠ê‚≠ê‚≠ê
def recognize_speech_from_bytes(audio_bytes: bytes, original_filename: str) -> str:
    logging.info(f"–ù–∞—á–∞–ª–æ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ä–µ—á–∏. –ü–æ–ª—É—á–µ–Ω–æ –±–∞–π—Ç–æ–≤: {len(audio_bytes)}")
    
    # –ü–æ–ª—É—á–∞–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ –∏–∑ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞, –ø—Ä–∏—Å–ª–∞–Ω–Ω–æ–≥–æ –∫–ª–∏–µ–Ω—Ç–æ–º
    file_extension = os.path.splitext(original_filename)[1] or ".webm"

    # --- –û–¢–õ–ê–î–ö–ê: –°–û–•–†–ê–ù–ï–ù–ò–ï –§–ê–ô–õ–û–í ---
    timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
    
    # 1. –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–æ, —á—Ç–æ –ø—Ä–∏—à–ª–æ –æ—Ç –∫–ª–∏–µ–Ω—Ç–∞, —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ–º
    input_filename = f"received_{timestamp}{file_extension}"
    with open(input_filename, "wb") as f:
        f.write(audio_bytes)
    logging.info(f"–í—Ö–æ–¥—è—â–∏–π –∞—É–¥–∏–æ—Ñ–∞–π–ª —Å–æ—Ö—Ä–∞–Ω–µ–Ω –∫–∞–∫ {input_filename}")
    # --- –ö–û–ù–ï–¶ –û–¢–õ–ê–î–ö–ò ---

    if len(audio_bytes) < 1000:
        raise ValueError("–ê—É–¥–∏–æ—Ñ–∞–π–ª —Å–ª–∏—à–∫–æ–º –º–∞–ª –∏–ª–∏ –ø—É—Å—Ç.")
        
    try:
        audio_segment = AudioSegment.from_file(io.BytesIO(audio_bytes))
        logging.info("–ê—É–¥–∏–æ —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–æ –≤ pydub –¥–ª—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏.")
        
        audio_segment = audio_segment.set_channels(1).set_frame_rate(16000)
        
        wav_buffer = io.BytesIO()
        audio_segment.export(wav_buffer, format="wav")
        wav_bytes = wav_buffer.getvalue()
        logging.info("–ê—É–¥–∏–æ —É—Å–ø–µ—à–Ω–æ —Å–∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ –≤ WAV 16kHz mono.")

        # --- –û–¢–õ–ê–î–ö–ê: –°–û–•–†–ê–ù–ï–ù–ò–ï –§–ê–ô–õ–û–í ---
        # 2. –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–æ, —á—Ç–æ –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤ Azure
        output_filename = f"to_azure_{timestamp}.wav"
        with open(output_filename, "wb") as f:
            f.write(wav_bytes)
        logging.info(f"–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π WAV-—Ñ–∞–π–ª —Å–æ—Ö—Ä–∞–Ω–µ–Ω –∫–∞–∫ {output_filename}")
        # --- –ö–û–ù–ï–¶ –û–¢–õ–ê–î–ö–ò ---

    except Exception as e:
        logging.error(f"üî• –û—à–∏–±–∫–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ –∞—É–¥–∏–æ —Å –ø–æ–º–æ—â—å—é pydub: {e}", exc_info=True)
        raise ValueError("–ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –∞—É–¥–∏–æ—Ñ–∞–π–ª. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ FFmpeg —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –Ω–∞ —Å–µ—Ä–≤–µ—Ä–µ.")

    speech_config = speechsdk.SpeechConfig(subscription=SPEECH_KEY, region=SPEECH_REGION, speech_recognition_language=SPEECH_RECOGNITION_LANGUAGE)
    stream = speechsdk.audio.PushAudioInputStream()
    audio_config = speechsdk.audio.AudioConfig(stream=stream)
    recognizer = speechsdk.SpeechRecognizer(speech_config=speech_config, audio_config=audio_config)
    
    stream.write(wav_bytes)
    stream.close()

    result = recognizer.recognize_once_async().get()

    if result.reason == speechsdk.ResultReason.RecognizedSpeech:
        if not result.text or result.text.isspace():
            logging.warning("–†–∞—Å–ø–æ–∑–Ω–∞–Ω –ø—É—Å—Ç–æ–π —Ç–µ–∫—Å—Ç.")
            raise ValueError("–†–∞—Å–ø–æ–∑–Ω–∞–Ω –ø—É—Å—Ç–æ–π —Ç–µ–∫—Å—Ç.")
        logging.info(f"–†–∞—Å–ø–æ–∑–Ω–∞–Ω–æ: '{result.text}'")
        return result.text
    elif result.reason == speechsdk.ResultReason.NoMatch:
        logging.warning("–†–µ—á—å –Ω–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–∞ (NoMatch).")
        raise ValueError("–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å —Ä–µ—á—å.")
    elif result.reason == speechsdk.ResultReason.Canceled:
        cancellation_details = result.cancellation_details
        logging.error(f"–û—à–∏–±–∫–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è (Canceled): {cancellation_details.reason}. –î–µ—Ç–∞–ª–∏: {cancellation_details.error_details}")
        raise RuntimeError(f"–û—à–∏–±–∫–∞ —Å–µ—Ä–≤–∏—Å–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è: {cancellation_details.reason}")
    
    raise RuntimeError("–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–∏ —Ä–µ—á–∏.")
# ‚≠ê‚≠ê‚≠ê –ö–û–ù–ï–¶ –ò–ó–ú–ï–ù–ï–ù–ò–ô –í –§–£–ù–ö–¶–ò–ò ‚≠ê‚≠ê‚≠ê


def get_answer_from_llm(question: str, history: List[Dict[str, str]]) -> str:
    # (–≠—Ç–∞ —Ñ—É–Ω–∫—Ü–∏—è –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π)
    messages = [{"role": "system", "content": SYSTEM_PROMPT}] + history + [{"role": "user", "content": question}]
    logging.info(f"–û—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –≤ Azure OpenAI —Å {len(messages)} —Å–æ–æ–±—â–µ–Ω–∏—è–º–∏.")
    try:
        response = AZURE_OPENAI_CLIENT.chat.completions.create(model=AZURE_OPENAI_DEPLOYMENT_NAME, messages=messages, temperature=0.7, max_tokens=150)
        answer = response.choices[0].message.content
        logging.info(f"–û—Ç–≤–µ—Ç –æ—Ç LLM –ø–æ–ª—É—á–µ–Ω: '{answer[:50]}...'")
        return answer
    except Exception as e:
        logging.error(f"üî• –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ Azure OpenAI: {e}", exc_info=True)
        raise RuntimeError("–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ —Å–µ—Ä–≤–∏—Å—É OpenAI.")


def synthesize_speech_from_text(text: str) -> bytes:
    # (–≠—Ç–∞ —Ñ—É–Ω–∫—Ü–∏—è –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π)
    logging.info(f"–ù–∞—á–∞–ª–æ —Å–∏–Ω—Ç–µ–∑–∞ —Ä–µ—á–∏ –¥–ª—è —Ç–µ–∫—Å—Ç–∞: '{text[:50]}...'")
    speech_config = speechsdk.SpeechConfig(subscription=SPEECH_KEY, region=SPEECH_REGION)
    speech_config.speech_synthesis_voice_name = SPEECH_VOICE_NAME
    speech_config.set_speech_synthesis_output_format(speechsdk.SpeechSynthesisOutputFormat.Audio16Khz32KBitRateMonoMp3)
    synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config, audio_config=None)
    result = synthesizer.speak_text_async(text).get()
    if result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:
        logging.info(f"–°–∏–Ω—Ç–µ–∑ —Ä–µ—á–∏ —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω. –†–∞–∑–º–µ—Ä –∞—É–¥–∏–æ: {len(result.audio_data)} –±–∞–π—Ç.")
        return result.audio_data
    cancellation_details = result.cancellation_details
    logging.error(f"–û—à–∏–±–∫–∞ —Å–∏–Ω—Ç–µ–∑–∞ —Ä–µ—á–∏: {cancellation_details.reason}. –î–µ—Ç–∞–ª–∏: {cancellation_details.error_details}")
    raise RuntimeError(f"–û—à–∏–±–∫–∞ —Å–µ—Ä–≤–∏—Å–∞ —Å–∏–Ω—Ç–µ–∑–∞ —Ä–µ—á–∏: {cancellation_details.reason}")


# --- 7. –§–∏–Ω–∞–ª—å–Ω—ã–π —ç–Ω–¥–ø–æ–∏–Ω—Ç ---
@app.post("/api/ask-assistant", response_model=AssistantResponse)
async def ask_assistant(
    audio_file: UploadFile = File(...),
    history_json: str = Form("[]")
):
    try:
        try:
            history = json.loads(history_json)
            if not isinstance(history, list):
                history = []
        except json.JSONDecodeError:
            raise HTTPException(status_code=400, detail="–ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç JSON –≤ –ø–æ–ª–µ history_json.")

        audio_bytes = await audio_file.read()
        
        # ‚≠ê –ü–µ—Ä–µ–¥–∞–µ–º –∏–º—è —Ñ–∞–π–ª–∞ –≤ —Ñ—É–Ω–∫—Ü–∏—é —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è
        recognized_text = recognize_speech_from_bytes(audio_bytes, audio_file.filename)
        
        answer_text = get_answer_from_llm(recognized_text, history)
        answer_audio_bytes = synthesize_speech_from_text(answer_text)
        audio_base64 = base64.b64encode(answer_audio_bytes).decode('utf-8')

        return AssistantResponse(
            userText=recognized_text,
            assistantText=answer_text,
            audioBase64=audio_base64
        )

    except ValueError as e:
        logging.warning(f"–û—à–∏–±–∫–∞ –¥–∞–Ω–Ω—ã—Ö –æ—Ç –∫–ª–∏–µ–Ω—Ç–∞ (400): {e}")
        raise HTTPException(status_code=400, detail=str(e))
    except Exception as e:
        logging.error("–ü—Ä–æ–∏–∑–æ—à–ª–∞ –Ω–µ–ø—Ä–µ–¥–≤–∏–¥–µ–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –≤ —ç–Ω–¥–ø–æ–∏–Ω—Ç–µ /api/ask-assistant", exc_info=True)
        raise HTTPException(status_code=500, detail="–ü—Ä–æ–∏–∑–æ—à–ª–∞ –Ω–µ–ø—Ä–µ–¥–≤–∏–¥–µ–Ω–Ω–∞—è –≤–Ω—É—Ç—Ä–µ–Ω–Ω—è—è –æ—à–∏–±–∫–∞ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞.")